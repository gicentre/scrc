## RAMPVIS / VIS4RAMP - Reflective Epidemiological Modelling Design Study Paper Proposal

##### Jason DYKES : 210205

<hr style="background-color:#fff ;height:0px; border:dashed 1px #e0e0e0"/>

There has been a lot of talk about papers and learnings and the like.

My ambition is to write a paper that draws upon a range of experiences through our various interactions _with the modelling folks_ during the funded RAMPVIS effort.

I'd like to follow a methodological approach that I have been involved in developing and that has been applied very persuasively and impressively in _Jen Rogers_ InfoVis paper from the _Utah Visualization Design Lab_.

They use an interpretivist perspective that offers "_opportunities for researchers to contribute knowledge that extends beyond visualization idioms and software_" and supports "_diverse range of knowledge contributions_".

In their _EvoBio Design Study_ paper (Rogers et al., 2020) they show how those doing applied visualization design work might go about "_using design study to acquire a more diverse range of knowledge, including knowledge about the visualization design process as well as about people’s relationship with data and technology more broadly_."

Their approach is based upon three _Criteria for Rigour in Design Study_ - that approaches should be :

 1. **abundant** - in terms of data collection and perspectives.
 So multiple engagements, modellers and designers would be helpful here.
 Data collection might involve a range of artefacts, perhaps including ...
    * discussion - zulip, email, etc
    * annotated meeting notes
    * presentations & position statements
    * sketches
    * papers & drafts
    * designs, design prototypes, design exposition and design discussion
    * reflective memos
    * etc.

 2. **reflexive** - accounting for the role of the researcher in the research and the effects of the research context on the researcher is important here.
 We are encouraged to embrace “_explicit and thoughtful self-awareness of a researcher’s own role in a study_”
 The research needs to be supported by systematic reflection with regular documented ...
    * _reflection in-action_ - e.g. reflective memo-ing, including reflexive practice (reflection on self), and
    * _reflection on-action_ - e.g. revisiting experiences, perhaps through ...

 3. **transparent** - in terms of the description of processes and presentation of annotated artefacts in a manner that ...
    * allows us to _record_ artefacts
    * supports ands encourages _reflection_
    * enables us to _report_ any claims by linking evidence (supporting the _generation_, _presentation_ and _checking_ of any claims made)
    * encourages _scrutiny_

If you are interested, I really recommend reading the paper - it's a pleasure! Here's [a version that I have annotated with some highlights on bits that I found useful and interesting for thinking about RAMPVIS](https://staff.city.ac.uk/~jad7/rampvis/rogers2020insights.210205.pdf).

It's a great read, particularly when read in conjunction with the interactive [**trrrace**](https://vdl.sci.utah.edu/trrrace/) system, developed to achieve much of the above:  https://vdl.sci.utah.edu/trrrace/

Here's the full reference and project Web page.

> **Rogers, J., Patton, A. H., Harmon, L., Lex, A., & Meyer, M. (2020)**. Insights From Experiments With Rigor in an EvoBio Design Study. _IEEE Transactions on Visualization and Computer Graphics_. https://vdl.sci.utah.edu/publications/2020_infovis_insights/

The [InfoVis Talk Video](https://youtu.be/0lIJarVNxcM) makes the key points really well.

Now, this work is inherently methodological and it's based upon a single interaction and I am not sure whether the _paper-within-a-paper_ model is one that we would want to adopt. But the idea of presenting evidence in a coherent manner that supports thinking and judgments about the plausibility of knowledge claims seems a good one to me. It's my ambition to achieve this kind of thing in RAMPVIS.

Some early thinking (_this is a non-exhaustive list of ideas generated during the EuroVIS paper writing_) about this suggests that we may have something to say on :

 - use of visualization in epidemiological modeling
 - design by immersion (see Hall et al., 2020) in lockdown (or the online workplace/workspace)
 - visualization design in a pandemic
 - specific approaches to COVID vis design

But recording our experiences, collating and annotating evidence and reflecting upon this (and other ideas as they arise) could result in some useful contributions with potentially persuasive evidence and a strong methodology to back it up.

---

#### Suggestions / Recommendations

There are some things to aim for based on direct recommendations and evident best practice in Rogers et al. (2020) ...

1. _establish systematic reflective practices_ from the outset - these should include reflexive notes, reflective transcriptions, and artifact curation
2. _build and maintain a trace_ of diverse research artifacts; and
3. when making claims, _argue for rigor from evidence_, not just methods
4. _engage critically and reflectively_ with research artifacts and experiences - look for things that changed, shifted, and surprised. Plan time for this!
5. memo - "_before and after meetings and during pivot- point moments in the research process_"
4. include of _direct links_ to research artifacts in resesarch papers to transparently provide an abundance of evidence
   - see [**trrrace**](https://vdl.sci.utah.edu/trrrace/), but we can think of other approaches that allow us to _record_, _reflect_ and _report_ too.

<!---
_How to Reflect_


_Tech for Reflection_

  --->
---

#### Things to Decide

This is just a start and there are various decisions to be made here - and I have done some thinking about this and will do some more. I'm happy to chat and hear suggestions too as we begin to develop answers!

But, among other things ...

 * how do we record record (what kind of artefacts? where are they logged? what are the metadata? do we log existing artefacts - if so, how?) - this is _tech_ plus _process_
 * when is the focus - what is the timeline?
 * how do we deal with individuals and anonymity?
 * how do we deal with artefacts that have already been recorded (volunteering phase)?
 * how do we deal with meeting recording and transcription?
 * how to we structure _reflection in-action_ - what kinds of memos?
 * how does this activity relate to (use? differentiate itself from? sit alongside?) the EuroVIS submission?
 * are we dealing with the future (funded activity), the past (volunteering activity) or both?
 * who is in (and what does that mean) - how wide or narrow is the range of experiences?

---

#### Guidance

The good news is that we have a fair bit of experience, and some nice technologies that may help out as we try to figure this out. And Rogers et al. (2020) provide some pretty helpful guidelines that might help us answer some of these questions. I would like to try to adhere to these :

 1. take reflective notes before and after interviews (interactions) with domain collaborators
 2. include reflexive considerations in your field notes (memos, etc.)
 3. audio-record interviews (screen record meetings) and analyze them via reflective transcription - soon after the interview
 4. revisit and reinterpret early notes and sketches (during ongoing _reflection in-action_)

Further reading and thinking about the paper might reveal more.

---

Evidently there is more to come, and I am trying to fit my working week into four days to spend Fridays reading, thinking, planning and hopefully working with RAMPVIS colleagues to develop a methodology and an actionable set of recommendations. The intention is to enable us to make some plausible and diverse contributions that "_that extend beyond visualization idioms and software_" and that will be useful to the VIS research community.

I'll circulate more next Friday.
Happy to hear reactions - public, private, here, anywhere.

**Jason** - _21/02/05_
